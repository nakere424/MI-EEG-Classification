{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brain_wave_EEGNet.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Nn"
      ],
      "metadata": {
        "id": "6nKAaKX5ha_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "\n",
        "# https://drive.google.com/file/d/1-yNmxWBM4Xtr70jAH5Hsp7lc2C0-KqgP/view\n",
        "!gdown  --id 1-yNmxWBM4Xtr70jAH5Hsp7lc2C0-KqgPT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdk8ZYYQFJcl",
        "outputId": "74a3d3e2-7d56-4a98-9cc8-449a779c7174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.2)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14774 sha256=a07af125d1a4091ffafd128847609530fcdd7ef16a2c3276b99317dcdb7746f7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z5x8eot4/wheels/fb/c3/0e/c4d8ff8bfcb0461afff199471449f642179b74968c15b7a69c\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.2.2\n",
            "    Uninstalling gdown-4.2.2:\n",
            "      Successfully uninstalled gdown-4.2.2\n",
            "Successfully installed gdown-4.4.0\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-WOEpbnCBRI_KOOvF2Vdx2km_N4bT4gT\n",
            "To: /content/cleanbynon.zip\n",
            "100% 6.71G/6.71G [00:26<00:00, 256MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/cleanbynon.zip -d /content/"
      ],
      "metadata": {
        "id": "gnpQJrvEL-s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pb"
      ],
      "metadata": {
        "id": "g4Klm5F72Tva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "\n",
        "# https://drive.google.com/file/d/1-p-HOzR1TUPubeqtpiMHh6rx1hi-jYec/view?usp=sharing\n",
        "!gdown  --id 1-p-HOzR1TUPubeqtpiMHh6rx1hi-jYec\n",
        "\n",
        "# https://drive.google.com/file/d/1oV7CAUqUgy1AekofXd9zpP6VF8L1H6rX/view?usp=sharing\n",
        "!gdown  --id 1oV7CAUqUgy1AekofXd9zpP6VF8L1H6rX\n",
        "\n",
        "# https://drive.google.com/file/d/1qDpQ4Vii3k2pGf7DnKx_uAywrsYgnS6-/view?usp=sharing\n",
        "!gdown  --id 1qDpQ4Vii3k2pGf7DnKx_uAywrsYgnS6-\n",
        "\n",
        "# https://drive.google.com/file/d/1EIh0x3Jese5ysn4jWuuYTrnkp3u0Igzw/view?usp=sharing\n",
        "!gdown  --id 1EIh0x3Jese5ysn4jWuuYTrnkp3u0Igzw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0Edqm3rHhn0",
        "outputId": "e04442da-360a-434f-8979-f0e4d3fc867e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-p-HOzR1TUPubeqtpiMHh6rx1hi-jYec\n",
            "To: /content/100Hz_data_sess1.npy.zip\n",
            "100% 1.31G/1.31G [00:04<00:00, 285MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1oV7CAUqUgy1AekofXd9zpP6VF8L1H6rX\n",
            "To: /content/100Hz_label_sess1.npy\n",
            "100% 20.9k/20.9k [00:00<00:00, 34.0MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qDpQ4Vii3k2pGf7DnKx_uAywrsYgnS6-\n",
            "To: /content/100Hz_data_sess2.zip\n",
            "100% 1.30G/1.30G [00:04<00:00, 272MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1EIh0x3Jese5ysn4jWuuYTrnkp3u0Igzw\n",
            "To: /content/100Hz_label_sess2.npy\n",
            "100% 20.9k/20.9k [00:00<00:00, 29.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/100Hz_data_sess1.npy.zip -d /content/\n",
        "!unzip -q /content/100Hz_data_sess2.zip -d /content/\n",
        "\n",
        "! rm /content/100Hz_data_sess1.npy.zip\n",
        "! rm /content/100Hz_data_sess2.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzpaCAkl3WnZ",
        "outputId": "883c2ab9-264e-4dac-8b0c-502712ebc935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace /content/100Hz_data_sess1.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/100Hz_data_sess2.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "8QKELU5r7Ogz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss1_data = np.load('/content/100Hz_data_sess1.npy')\n",
        "ss1_label = np.load('/content/100Hz_label_sess1.npy')\n",
        "\n",
        "ss2_data = np.load('/content/100Hz_data_sess2.npy')\n",
        "ss2_label = np.load('/content/100Hz_label_sess2.npy')"
      ],
      "metadata": {
        "id": "aO7GryqF64fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index_to_take = [i for start in range(200,20601,400) for i in range(start,start+200)] \n",
        "# ss1_data = ss1_data[index_to_take,:,:] \n",
        "# ss1_label = ss1_label[index_to_take]"
      ],
      "metadata": {
        "id": "doc75LVvXXKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index_to_take = [i for start in range(200,20601,400) for i in range(start,start+200)] \n",
        "# ss2_data = ss2_data[index_to_take,:,:] \n",
        "# ss2_label = ss2_label[index_to_take]"
      ],
      "metadata": {
        "id": "woPgBLimXYvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.concatenate([ss1_data, ss2_data])\n",
        "label = np.concatenate([ss1_label, ss2_label])"
      ],
      "metadata": {
        "id": "vxrOWi8BAwMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del ss1_data\n",
        "del ss1_label\n",
        "del ss2_data\n",
        "del ss2_label"
      ],
      "metadata": {
        "id": "e2mrWa_kmhOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9awXIugPvdw",
        "outputId": "b36f24af-3d7e-4fe5-b936-14e41e7ffb61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41600, 400, 62)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_input = np.moveaxis(np.expand_dims(data, axis = 1), 2, 3)"
      ],
      "metadata": {
        "id": "JiBqQj5DxQDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en8GEUMlxozU",
        "outputId": "1b7e5996-56eb-4969-ead4-eb9a792adc61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41600, 1, 62, 400)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X, X_test, y, y_test = train_test_split(data_input, label, test_size=0.1, random_state=42)\n",
        "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "M3hvPg2pQ7Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del data\n",
        "del data_input\n",
        "# del X\n",
        "# del y"
      ],
      "metadata": {
        "id": "dAwNPVwjm47T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train))\n",
        "print(len(X_val))\n",
        "print(len(X_test))\n",
        "print(len(y_train))\n",
        "print(len(y_val))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97yNCI2CbV8o",
        "outputId": "dc095bea-49b2-449e-d2de-ee94aab9b703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33696\n",
            "3744\n",
            "4160\n",
            "33696\n",
            "3744\n",
            "4160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EEGNet"
      ],
      "metadata": {
        "id": "TmTN-KaThh4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install min2net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYyag8vQOHJK",
        "outputId": "92defc20-b408-4f52-92a4-849aa6c4487a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: min2net in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.37.0 in /usr/local/lib/python3.7/dist-packages (from min2net) (0.37.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.7/dist-packages (from min2net) (1.0.2)\n",
            "Requirement already satisfied: tensorflow-addons==0.9.1 in /usr/local/lib/python3.7/dist-packages (from min2net) (0.9.1)\n",
            "Requirement already satisfied: wget>=3.2 in /usr/local/lib/python3.7/dist-packages (from min2net) (3.2)\n",
            "Requirement already satisfied: setuptools>=42 in /usr/local/lib/python3.7/dist-packages (from min2net) (57.4.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons==0.9.1->min2net) (2.7.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->min2net) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->min2net) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->min2net) (1.21.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->min2net) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import min2net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poJqlC9XOZKd",
        "outputId": "76b75afb-5643-4931-9b86-a80675990954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.1.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from min2net.model import EEGNet\n",
        "# import ndarray as np\n",
        "\n",
        "model = EEGNet(input_shape=(1,62,400), num_class=4, dropout_rate=0.25, shuffle=True)"
      ],
      "metadata": {
        "id": "XEC8OzcaOfB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-eLLmeEQZZx",
        "outputId": "aacdcb0a-a00e-455e-d34f-fdd4690c62ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1, 62, 400)]      0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 8, 62, 400)        1600      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 8, 62, 400)       1600      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " depthwise_conv2d (Depthwise  (None, 16, 1, 400)       992       \n",
            " Conv2D)                                                         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 1, 400)       1600      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 16, 1, 400)        0         \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 16, 1, 100)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 1, 100)        0         \n",
            "                                                                 \n",
            " separable_conv2d (Separable  (None, 16, 1, 100)       1056      \n",
            " Conv2D)                                                         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 1, 100)       400       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 16, 1, 100)        0         \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 16, 1, 12)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16, 1, 12)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 192)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 772       \n",
            "                                                                 \n",
            " softmax (Activation)        (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,020\n",
            "Trainable params: 6,220\n",
            "Non-trainable params: 1,800\n",
            "_________________________________________________________________\n",
            "The first kernel size is (1, 200)\n",
            "Epoch 1/200\n",
            "  6/375 [..............................] - ETA: 35s - loss: 1.4243 - accuracy: 0.2800WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0155s vs `on_train_batch_end` time: 0.0775s). Check your callbacks.\n",
            "375/375 [==============================] - ETA: 0s - loss: 1.0380 - accuracy: 0.5416\n",
            "Epoch 1: val_loss improved from inf to 0.89470, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 46s 99ms/step - loss: 1.0380 - accuracy: 0.5416 - val_loss: 0.8947 - val_accuracy: 0.6046 - lr: 0.0100\n",
            "Epoch 2/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.8587 - accuracy: 0.6182\n",
            "Epoch 2: val_loss improved from 0.89470 to 0.85702, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.8587 - accuracy: 0.6182 - val_loss: 0.8570 - val_accuracy: 0.6173 - lr: 0.0100\n",
            "Epoch 3/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.8269 - accuracy: 0.6233\n",
            "Epoch 3: val_loss improved from 0.85702 to 0.81569, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.8270 - accuracy: 0.6232 - val_loss: 0.8157 - val_accuracy: 0.6123 - lr: 0.0100\n",
            "Epoch 4/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.7928 - accuracy: 0.6403\n",
            "Epoch 4: val_loss improved from 0.81569 to 0.75678, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.7926 - accuracy: 0.6405 - val_loss: 0.7568 - val_accuracy: 0.6630 - lr: 0.0100\n",
            "Epoch 5/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.7796 - accuracy: 0.6457\n",
            "Epoch 5: val_loss improved from 0.75678 to 0.73875, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.7796 - accuracy: 0.6457 - val_loss: 0.7387 - val_accuracy: 0.6608 - lr: 0.0100\n",
            "Epoch 6/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.7619 - accuracy: 0.6511\n",
            "Epoch 6: val_loss improved from 0.73875 to 0.73300, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.7619 - accuracy: 0.6512 - val_loss: 0.7330 - val_accuracy: 0.6587 - lr: 0.0100\n",
            "Epoch 7/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.7512 - accuracy: 0.6572\n",
            "Epoch 7: val_loss improved from 0.73300 to 0.72615, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.7512 - accuracy: 0.6572 - val_loss: 0.7262 - val_accuracy: 0.6531 - lr: 0.0100\n",
            "Epoch 8/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.7415 - accuracy: 0.6570\n",
            "Epoch 8: val_loss improved from 0.72615 to 0.70913, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.7415 - accuracy: 0.6569 - val_loss: 0.7091 - val_accuracy: 0.6613 - lr: 0.0100\n",
            "Epoch 9/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.7299 - accuracy: 0.6624\n",
            "Epoch 9: val_loss improved from 0.70913 to 0.67509, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.7301 - accuracy: 0.6623 - val_loss: 0.6751 - val_accuracy: 0.6800 - lr: 0.0100\n",
            "Epoch 10/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.7203 - accuracy: 0.6675\n",
            "Epoch 10: val_loss did not improve from 0.67509\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.7204 - accuracy: 0.6675 - val_loss: 0.7032 - val_accuracy: 0.6810 - lr: 0.0100\n",
            "Epoch 11/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.7019 - accuracy: 0.6761\n",
            "Epoch 11: val_loss improved from 0.67509 to 0.62937, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.7018 - accuracy: 0.6761 - val_loss: 0.6294 - val_accuracy: 0.7224 - lr: 0.0100\n",
            "Epoch 12/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6840 - accuracy: 0.6842\n",
            "Epoch 12: val_loss did not improve from 0.62937\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6839 - accuracy: 0.6842 - val_loss: 0.6396 - val_accuracy: 0.7034 - lr: 0.0100\n",
            "Epoch 13/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6690 - accuracy: 0.6956\n",
            "Epoch 13: val_loss did not improve from 0.62937\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6692 - accuracy: 0.6956 - val_loss: 0.6624 - val_accuracy: 0.6834 - lr: 0.0100\n",
            "Epoch 14/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6749 - accuracy: 0.6908\n",
            "Epoch 14: val_loss improved from 0.62937 to 0.61204, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6749 - accuracy: 0.6908 - val_loss: 0.6120 - val_accuracy: 0.7380 - lr: 0.0100\n",
            "Epoch 15/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6660 - accuracy: 0.6954\n",
            "Epoch 15: val_loss improved from 0.61204 to 0.59436, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6660 - accuracy: 0.6954 - val_loss: 0.5944 - val_accuracy: 0.7284 - lr: 0.0100\n",
            "Epoch 16/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6676 - accuracy: 0.6970\n",
            "Epoch 16: val_loss did not improve from 0.59436\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6676 - accuracy: 0.6970 - val_loss: 0.6200 - val_accuracy: 0.7183 - lr: 0.0100\n",
            "Epoch 17/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6610 - accuracy: 0.7015\n",
            "Epoch 17: val_loss did not improve from 0.59436\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6612 - accuracy: 0.7016 - val_loss: 0.5960 - val_accuracy: 0.7430 - lr: 0.0100\n",
            "Epoch 18/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6608 - accuracy: 0.6992\n",
            "Epoch 18: val_loss did not improve from 0.59436\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6607 - accuracy: 0.6991 - val_loss: 0.6196 - val_accuracy: 0.7175 - lr: 0.0100\n",
            "Epoch 19/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6626 - accuracy: 0.7022\n",
            "Epoch 19: val_loss did not improve from 0.59436\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6626 - accuracy: 0.7021 - val_loss: 0.6204 - val_accuracy: 0.7320 - lr: 0.0100\n",
            "Epoch 20/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6529 - accuracy: 0.7071\n",
            "Epoch 20: val_loss did not improve from 0.59436\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6532 - accuracy: 0.7069 - val_loss: 0.6046 - val_accuracy: 0.7341 - lr: 0.0100\n",
            "Epoch 21/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6557 - accuracy: 0.7073\n",
            "Epoch 21: val_loss did not improve from 0.59436\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6560 - accuracy: 0.7071 - val_loss: 0.6639 - val_accuracy: 0.7079 - lr: 0.0100\n",
            "Epoch 22/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6478 - accuracy: 0.7050\n",
            "Epoch 22: val_loss did not improve from 0.59436\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6477 - accuracy: 0.7050 - val_loss: 0.6251 - val_accuracy: 0.7202 - lr: 0.0100\n",
            "Epoch 23/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6419 - accuracy: 0.7135\n",
            "Epoch 23: val_loss improved from 0.59436 to 0.58737, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6423 - accuracy: 0.7134 - val_loss: 0.5874 - val_accuracy: 0.7442 - lr: 0.0100\n",
            "Epoch 24/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6446 - accuracy: 0.7081\n",
            "Epoch 24: val_loss improved from 0.58737 to 0.57971, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6447 - accuracy: 0.7081 - val_loss: 0.5797 - val_accuracy: 0.7474 - lr: 0.0100\n",
            "Epoch 25/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6510 - accuracy: 0.7075\n",
            "Epoch 25: val_loss did not improve from 0.57971\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6510 - accuracy: 0.7076 - val_loss: 0.5988 - val_accuracy: 0.7298 - lr: 0.0100\n",
            "Epoch 26/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6515 - accuracy: 0.7087\n",
            "Epoch 26: val_loss did not improve from 0.57971\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6515 - accuracy: 0.7088 - val_loss: 0.6143 - val_accuracy: 0.7284 - lr: 0.0100\n",
            "Epoch 27/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6367 - accuracy: 0.7157\n",
            "Epoch 27: val_loss improved from 0.57971 to 0.57859, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6368 - accuracy: 0.7156 - val_loss: 0.5786 - val_accuracy: 0.7563 - lr: 0.0100\n",
            "Epoch 28/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6407 - accuracy: 0.7143\n",
            "Epoch 28: val_loss improved from 0.57859 to 0.56536, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 37s 97ms/step - loss: 0.6405 - accuracy: 0.7144 - val_loss: 0.5654 - val_accuracy: 0.7570 - lr: 0.0100\n",
            "Epoch 29/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6395 - accuracy: 0.7125\n",
            "Epoch 29: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6395 - accuracy: 0.7124 - val_loss: 0.5947 - val_accuracy: 0.7450 - lr: 0.0100\n",
            "Epoch 30/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6362 - accuracy: 0.7151\n",
            "Epoch 30: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6363 - accuracy: 0.7151 - val_loss: 0.6490 - val_accuracy: 0.7070 - lr: 0.0100\n",
            "Epoch 31/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6371 - accuracy: 0.7167\n",
            "Epoch 31: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6371 - accuracy: 0.7166 - val_loss: 0.5904 - val_accuracy: 0.7450 - lr: 0.0100\n",
            "Epoch 32/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6342 - accuracy: 0.7160\n",
            "Epoch 32: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6340 - accuracy: 0.7160 - val_loss: 0.5962 - val_accuracy: 0.7363 - lr: 0.0100\n",
            "Epoch 33/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6345 - accuracy: 0.7144\n",
            "Epoch 33: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6346 - accuracy: 0.7144 - val_loss: 0.6547 - val_accuracy: 0.7036 - lr: 0.0100\n",
            "Epoch 34/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6298 - accuracy: 0.7144\n",
            "Epoch 34: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6298 - accuracy: 0.7145 - val_loss: 0.5833 - val_accuracy: 0.7435 - lr: 0.0100\n",
            "Epoch 35/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6306 - accuracy: 0.7176\n",
            "Epoch 35: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6307 - accuracy: 0.7177 - val_loss: 0.6255 - val_accuracy: 0.7312 - lr: 0.0100\n",
            "Epoch 36/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6335 - accuracy: 0.7168\n",
            "Epoch 36: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6339 - accuracy: 0.7167 - val_loss: 0.6256 - val_accuracy: 0.7286 - lr: 0.0100\n",
            "Epoch 37/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6281 - accuracy: 0.7206\n",
            "Epoch 37: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6281 - accuracy: 0.7205 - val_loss: 0.6148 - val_accuracy: 0.7276 - lr: 0.0100\n",
            "Epoch 38/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6279 - accuracy: 0.7198\n",
            "Epoch 38: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6279 - accuracy: 0.7197 - val_loss: 0.5894 - val_accuracy: 0.7423 - lr: 0.0100\n",
            "Epoch 39/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6261 - accuracy: 0.7201\n",
            "Epoch 39: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6262 - accuracy: 0.7201 - val_loss: 0.5969 - val_accuracy: 0.7310 - lr: 0.0100\n",
            "Epoch 40/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6313 - accuracy: 0.7167\n",
            "Epoch 40: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6313 - accuracy: 0.7167 - val_loss: 0.6194 - val_accuracy: 0.7185 - lr: 0.0100\n",
            "Epoch 41/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6280 - accuracy: 0.7206\n",
            "Epoch 41: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6280 - accuracy: 0.7206 - val_loss: 0.5656 - val_accuracy: 0.7538 - lr: 0.0100\n",
            "Epoch 42/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6232 - accuracy: 0.7187\n",
            "Epoch 42: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6234 - accuracy: 0.7186 - val_loss: 0.5764 - val_accuracy: 0.7558 - lr: 0.0100\n",
            "Epoch 43/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6299 - accuracy: 0.7163\n",
            "Epoch 43: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6299 - accuracy: 0.7162 - val_loss: 0.6023 - val_accuracy: 0.7288 - lr: 0.0100\n",
            "Epoch 44/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6203 - accuracy: 0.7225\n",
            "Epoch 44: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6203 - accuracy: 0.7226 - val_loss: 0.5969 - val_accuracy: 0.7368 - lr: 0.0100\n",
            "Epoch 45/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6237 - accuracy: 0.7210\n",
            "Epoch 45: val_loss did not improve from 0.56536\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6236 - accuracy: 0.7210 - val_loss: 0.5940 - val_accuracy: 0.7401 - lr: 0.0100\n",
            "Epoch 46/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6289 - accuracy: 0.7210\n",
            "Epoch 46: val_loss improved from 0.56536 to 0.55829, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6289 - accuracy: 0.7209 - val_loss: 0.5583 - val_accuracy: 0.7632 - lr: 0.0100\n",
            "Epoch 47/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6161 - accuracy: 0.7251\n",
            "Epoch 47: val_loss did not improve from 0.55829\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6164 - accuracy: 0.7249 - val_loss: 0.5957 - val_accuracy: 0.7365 - lr: 0.0100\n",
            "Epoch 48/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6164 - accuracy: 0.7258\n",
            "Epoch 48: val_loss did not improve from 0.55829\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6169 - accuracy: 0.7257 - val_loss: 0.5939 - val_accuracy: 0.7380 - lr: 0.0100\n",
            "Epoch 49/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6267 - accuracy: 0.7171\n",
            "Epoch 49: val_loss did not improve from 0.55829\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6267 - accuracy: 0.7171 - val_loss: 0.5898 - val_accuracy: 0.7493 - lr: 0.0100\n",
            "Epoch 50/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6176 - accuracy: 0.7231\n",
            "Epoch 50: val_loss did not improve from 0.55829\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6176 - accuracy: 0.7231 - val_loss: 0.5588 - val_accuracy: 0.7608 - lr: 0.0100\n",
            "Epoch 51/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6197 - accuracy: 0.7217\n",
            "Epoch 51: val_loss did not improve from 0.55829\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6196 - accuracy: 0.7217 - val_loss: 0.5619 - val_accuracy: 0.7570 - lr: 0.0100\n",
            "Epoch 52/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6214 - accuracy: 0.7203\n",
            "Epoch 52: val_loss did not improve from 0.55829\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6216 - accuracy: 0.7203 - val_loss: 0.6109 - val_accuracy: 0.7250 - lr: 0.0100\n",
            "Epoch 53/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6226 - accuracy: 0.7194\n",
            "Epoch 53: val_loss did not improve from 0.55829\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6226 - accuracy: 0.7195 - val_loss: 0.5811 - val_accuracy: 0.7433 - lr: 0.0100\n",
            "Epoch 54/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6208 - accuracy: 0.7212\n",
            "Epoch 54: val_loss improved from 0.55829 to 0.55363, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6207 - accuracy: 0.7213 - val_loss: 0.5536 - val_accuracy: 0.7627 - lr: 0.0100\n",
            "Epoch 55/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6124 - accuracy: 0.7261\n",
            "Epoch 55: val_loss did not improve from 0.55363\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6125 - accuracy: 0.7261 - val_loss: 0.5644 - val_accuracy: 0.7466 - lr: 0.0100\n",
            "Epoch 56/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6166 - accuracy: 0.7252\n",
            "Epoch 56: val_loss did not improve from 0.55363\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6165 - accuracy: 0.7252 - val_loss: 0.5762 - val_accuracy: 0.7454 - lr: 0.0100\n",
            "Epoch 57/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6156 - accuracy: 0.7239\n",
            "Epoch 57: val_loss did not improve from 0.55363\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6159 - accuracy: 0.7238 - val_loss: 0.5983 - val_accuracy: 0.7351 - lr: 0.0100\n",
            "Epoch 58/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6160 - accuracy: 0.7245\n",
            "Epoch 58: val_loss did not improve from 0.55363\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6159 - accuracy: 0.7246 - val_loss: 0.5562 - val_accuracy: 0.7541 - lr: 0.0100\n",
            "Epoch 59/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6135 - accuracy: 0.7280\n",
            "Epoch 59: val_loss did not improve from 0.55363\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6141 - accuracy: 0.7278 - val_loss: 0.5860 - val_accuracy: 0.7541 - lr: 0.0100\n",
            "Epoch 60/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6141 - accuracy: 0.7279\n",
            "Epoch 60: val_loss improved from 0.55363 to 0.55276, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6141 - accuracy: 0.7279 - val_loss: 0.5528 - val_accuracy: 0.7541 - lr: 0.0100\n",
            "Epoch 61/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6110 - accuracy: 0.7257\n",
            "Epoch 61: val_loss did not improve from 0.55276\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6109 - accuracy: 0.7257 - val_loss: 0.5862 - val_accuracy: 0.7536 - lr: 0.0100\n",
            "Epoch 62/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6198 - accuracy: 0.7232\n",
            "Epoch 62: val_loss did not improve from 0.55276\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.6199 - accuracy: 0.7232 - val_loss: 0.5998 - val_accuracy: 0.7373 - lr: 0.0100\n",
            "Epoch 63/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6080 - accuracy: 0.7300\n",
            "Epoch 63: val_loss did not improve from 0.55276\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6080 - accuracy: 0.7300 - val_loss: 0.5564 - val_accuracy: 0.7608 - lr: 0.0100\n",
            "Epoch 64/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6165 - accuracy: 0.7234\n",
            "Epoch 64: val_loss did not improve from 0.55276\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6166 - accuracy: 0.7233 - val_loss: 0.5537 - val_accuracy: 0.7632 - lr: 0.0100\n",
            "Epoch 65/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6068 - accuracy: 0.7308\n",
            "Epoch 65: val_loss did not improve from 0.55276\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6069 - accuracy: 0.7308 - val_loss: 0.5617 - val_accuracy: 0.7531 - lr: 0.0100\n",
            "Epoch 66/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6130 - accuracy: 0.7268\n",
            "Epoch 66: val_loss did not improve from 0.55276\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6131 - accuracy: 0.7267 - val_loss: 0.5572 - val_accuracy: 0.7541 - lr: 0.0100\n",
            "Epoch 67/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6108 - accuracy: 0.7276\n",
            "Epoch 67: val_loss did not improve from 0.55276\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6110 - accuracy: 0.7276 - val_loss: 0.5615 - val_accuracy: 0.7495 - lr: 0.0100\n",
            "Epoch 68/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6077 - accuracy: 0.7317\n",
            "Epoch 68: val_loss improved from 0.55276 to 0.54670, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6078 - accuracy: 0.7318 - val_loss: 0.5467 - val_accuracy: 0.7659 - lr: 0.0100\n",
            "Epoch 69/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6100 - accuracy: 0.7282\n",
            "Epoch 69: val_loss did not improve from 0.54670\n",
            "375/375 [==============================] - 37s 97ms/step - loss: 0.6102 - accuracy: 0.7281 - val_loss: 0.5641 - val_accuracy: 0.7510 - lr: 0.0100\n",
            "Epoch 70/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6060 - accuracy: 0.7306\n",
            "Epoch 70: val_loss did not improve from 0.54670\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6058 - accuracy: 0.7308 - val_loss: 0.5709 - val_accuracy: 0.7575 - lr: 0.0100\n",
            "Epoch 71/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6102 - accuracy: 0.7295\n",
            "Epoch 71: val_loss did not improve from 0.54670\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6101 - accuracy: 0.7296 - val_loss: 0.5607 - val_accuracy: 0.7529 - lr: 0.0100\n",
            "Epoch 72/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6102 - accuracy: 0.7300\n",
            "Epoch 72: val_loss did not improve from 0.54670\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6102 - accuracy: 0.7299 - val_loss: 0.5666 - val_accuracy: 0.7546 - lr: 0.0100\n",
            "Epoch 73/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6086 - accuracy: 0.7290\n",
            "Epoch 73: val_loss did not improve from 0.54670\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6088 - accuracy: 0.7288 - val_loss: 0.5562 - val_accuracy: 0.7512 - lr: 0.0100\n",
            "Epoch 74/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6126 - accuracy: 0.7261\n",
            "Epoch 74: val_loss did not improve from 0.54670\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6126 - accuracy: 0.7261 - val_loss: 0.5521 - val_accuracy: 0.7603 - lr: 0.0100\n",
            "Epoch 75/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6121 - accuracy: 0.7270\n",
            "Epoch 75: val_loss did not improve from 0.54670\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6123 - accuracy: 0.7271 - val_loss: 0.5773 - val_accuracy: 0.7440 - lr: 0.0100\n",
            "Epoch 76/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6081 - accuracy: 0.7287\n",
            "Epoch 76: val_loss did not improve from 0.54670\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6080 - accuracy: 0.7287 - val_loss: 0.5638 - val_accuracy: 0.7690 - lr: 0.0100\n",
            "Epoch 77/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6061 - accuracy: 0.7290\n",
            "Epoch 77: val_loss did not improve from 0.54670\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6062 - accuracy: 0.7289 - val_loss: 0.5695 - val_accuracy: 0.7536 - lr: 0.0100\n",
            "Epoch 78/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6103 - accuracy: 0.7270\n",
            "Epoch 78: val_loss did not improve from 0.54670\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6105 - accuracy: 0.7269 - val_loss: 0.5862 - val_accuracy: 0.7450 - lr: 0.0100\n",
            "Epoch 79/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6087 - accuracy: 0.7285\n",
            "Epoch 79: val_loss did not improve from 0.54670\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6087 - accuracy: 0.7284 - val_loss: 0.5731 - val_accuracy: 0.7584 - lr: 0.0100\n",
            "Epoch 80/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6123 - accuracy: 0.7242\n",
            "Epoch 80: val_loss did not improve from 0.54670\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6122 - accuracy: 0.7242 - val_loss: 0.5772 - val_accuracy: 0.7538 - lr: 0.0100\n",
            "Epoch 81/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5986 - accuracy: 0.7332\n",
            "Epoch 81: val_loss improved from 0.54670 to 0.53980, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5982 - accuracy: 0.7333 - val_loss: 0.5398 - val_accuracy: 0.7683 - lr: 0.0100\n",
            "Epoch 82/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6115 - accuracy: 0.7272\n",
            "Epoch 82: val_loss did not improve from 0.53980\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6115 - accuracy: 0.7272 - val_loss: 0.5672 - val_accuracy: 0.7656 - lr: 0.0100\n",
            "Epoch 83/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6051 - accuracy: 0.7308\n",
            "Epoch 83: val_loss did not improve from 0.53980\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6052 - accuracy: 0.7309 - val_loss: 0.5682 - val_accuracy: 0.7493 - lr: 0.0100\n",
            "Epoch 84/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6159 - accuracy: 0.7268\n",
            "Epoch 84: val_loss did not improve from 0.53980\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6159 - accuracy: 0.7267 - val_loss: 0.6085 - val_accuracy: 0.7125 - lr: 0.0100\n",
            "Epoch 85/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6035 - accuracy: 0.7322\n",
            "Epoch 85: val_loss improved from 0.53980 to 0.53963, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6035 - accuracy: 0.7322 - val_loss: 0.5396 - val_accuracy: 0.7678 - lr: 0.0100\n",
            "Epoch 86/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6054 - accuracy: 0.7299\n",
            "Epoch 86: val_loss did not improve from 0.53963\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6055 - accuracy: 0.7298 - val_loss: 0.5597 - val_accuracy: 0.7555 - lr: 0.0100\n",
            "Epoch 87/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6033 - accuracy: 0.7340\n",
            "Epoch 87: val_loss did not improve from 0.53963\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6032 - accuracy: 0.7340 - val_loss: 0.5907 - val_accuracy: 0.7416 - lr: 0.0100\n",
            "Epoch 88/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6101 - accuracy: 0.7272\n",
            "Epoch 88: val_loss did not improve from 0.53963\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6099 - accuracy: 0.7272 - val_loss: 0.5614 - val_accuracy: 0.7589 - lr: 0.0100\n",
            "Epoch 89/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6055 - accuracy: 0.7286\n",
            "Epoch 89: val_loss did not improve from 0.53963\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6057 - accuracy: 0.7284 - val_loss: 0.5555 - val_accuracy: 0.7546 - lr: 0.0100\n",
            "Epoch 90/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6029 - accuracy: 0.7294\n",
            "Epoch 90: val_loss did not improve from 0.53963\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6028 - accuracy: 0.7296 - val_loss: 0.5967 - val_accuracy: 0.7387 - lr: 0.0100\n",
            "Epoch 91/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6104 - accuracy: 0.7253\n",
            "Epoch 91: val_loss did not improve from 0.53963\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6103 - accuracy: 0.7254 - val_loss: 0.5626 - val_accuracy: 0.7493 - lr: 0.0100\n",
            "Epoch 92/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6134 - accuracy: 0.7271\n",
            "Epoch 92: val_loss did not improve from 0.53963\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6136 - accuracy: 0.7270 - val_loss: 0.5808 - val_accuracy: 0.7435 - lr: 0.0100\n",
            "Epoch 93/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5989 - accuracy: 0.7342\n",
            "Epoch 93: val_loss did not improve from 0.53963\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5988 - accuracy: 0.7343 - val_loss: 0.5657 - val_accuracy: 0.7457 - lr: 0.0100\n",
            "Epoch 94/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6016 - accuracy: 0.7305\n",
            "Epoch 94: val_loss did not improve from 0.53963\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6018 - accuracy: 0.7304 - val_loss: 0.6153 - val_accuracy: 0.7065 - lr: 0.0100\n",
            "Epoch 95/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6014 - accuracy: 0.7303\n",
            "Epoch 95: val_loss improved from 0.53963 to 0.53696, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 37s 97ms/step - loss: 0.6013 - accuracy: 0.7304 - val_loss: 0.5370 - val_accuracy: 0.7712 - lr: 0.0100\n",
            "Epoch 96/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6000 - accuracy: 0.7315\n",
            "Epoch 96: val_loss did not improve from 0.53696\n",
            "375/375 [==============================] - 37s 97ms/step - loss: 0.5999 - accuracy: 0.7314 - val_loss: 0.5527 - val_accuracy: 0.7666 - lr: 0.0100\n",
            "Epoch 97/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5991 - accuracy: 0.7322\n",
            "Epoch 97: val_loss did not improve from 0.53696\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5992 - accuracy: 0.7322 - val_loss: 0.5907 - val_accuracy: 0.7392 - lr: 0.0100\n",
            "Epoch 98/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6059 - accuracy: 0.7303\n",
            "Epoch 98: val_loss did not improve from 0.53696\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6061 - accuracy: 0.7302 - val_loss: 0.5412 - val_accuracy: 0.7627 - lr: 0.0100\n",
            "Epoch 99/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6043 - accuracy: 0.7299\n",
            "Epoch 99: val_loss did not improve from 0.53696\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6045 - accuracy: 0.7298 - val_loss: 0.5410 - val_accuracy: 0.7649 - lr: 0.0100\n",
            "Epoch 100/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6013 - accuracy: 0.7304\n",
            "Epoch 100: val_loss improved from 0.53696 to 0.53582, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6013 - accuracy: 0.7304 - val_loss: 0.5358 - val_accuracy: 0.7620 - lr: 0.0100\n",
            "Epoch 101/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5985 - accuracy: 0.7334\n",
            "Epoch 101: val_loss did not improve from 0.53582\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5986 - accuracy: 0.7334 - val_loss: 0.5944 - val_accuracy: 0.7474 - lr: 0.0100\n",
            "Epoch 102/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5997 - accuracy: 0.7337\n",
            "Epoch 102: val_loss did not improve from 0.53582\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5998 - accuracy: 0.7336 - val_loss: 0.5569 - val_accuracy: 0.7541 - lr: 0.0100\n",
            "Epoch 103/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6060 - accuracy: 0.7298\n",
            "Epoch 103: val_loss did not improve from 0.53582\n",
            "375/375 [==============================] - 37s 97ms/step - loss: 0.6060 - accuracy: 0.7299 - val_loss: 0.6212 - val_accuracy: 0.7178 - lr: 0.0100\n",
            "Epoch 104/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6014 - accuracy: 0.7330\n",
            "Epoch 104: val_loss did not improve from 0.53582\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6014 - accuracy: 0.7330 - val_loss: 0.5828 - val_accuracy: 0.7418 - lr: 0.0100\n",
            "Epoch 105/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6048 - accuracy: 0.7319\n",
            "Epoch 105: val_loss did not improve from 0.53582\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6050 - accuracy: 0.7319 - val_loss: 0.5660 - val_accuracy: 0.7553 - lr: 0.0100\n",
            "Epoch 106/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6003 - accuracy: 0.7319\n",
            "Epoch 106: val_loss did not improve from 0.53582\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6003 - accuracy: 0.7320 - val_loss: 0.6049 - val_accuracy: 0.7418 - lr: 0.0100\n",
            "Epoch 107/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5993 - accuracy: 0.7329\n",
            "Epoch 107: val_loss did not improve from 0.53582\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5993 - accuracy: 0.7329 - val_loss: 0.5446 - val_accuracy: 0.7728 - lr: 0.0100\n",
            "Epoch 108/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6022 - accuracy: 0.7298\n",
            "Epoch 108: val_loss did not improve from 0.53582\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6022 - accuracy: 0.7297 - val_loss: 0.5756 - val_accuracy: 0.7447 - lr: 0.0100\n",
            "Epoch 109/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6003 - accuracy: 0.7339\n",
            "Epoch 109: val_loss did not improve from 0.53582\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6003 - accuracy: 0.7338 - val_loss: 0.5734 - val_accuracy: 0.7469 - lr: 0.0100\n",
            "Epoch 110/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6047 - accuracy: 0.7305\n",
            "Epoch 110: val_loss improved from 0.53582 to 0.51710, saving model to logs/EEGNet_out_weights.h5\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6047 - accuracy: 0.7305 - val_loss: 0.5171 - val_accuracy: 0.7769 - lr: 0.0100\n",
            "Epoch 111/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6012 - accuracy: 0.7297\n",
            "Epoch 111: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6012 - accuracy: 0.7298 - val_loss: 0.5515 - val_accuracy: 0.7498 - lr: 0.0100\n",
            "Epoch 112/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5997 - accuracy: 0.7330\n",
            "Epoch 112: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5997 - accuracy: 0.7329 - val_loss: 0.5747 - val_accuracy: 0.7577 - lr: 0.0100\n",
            "Epoch 113/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5993 - accuracy: 0.7326\n",
            "Epoch 113: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5994 - accuracy: 0.7326 - val_loss: 0.5736 - val_accuracy: 0.7462 - lr: 0.0100\n",
            "Epoch 114/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5967 - accuracy: 0.7350\n",
            "Epoch 114: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5967 - accuracy: 0.7350 - val_loss: 0.5483 - val_accuracy: 0.7707 - lr: 0.0100\n",
            "Epoch 115/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5965 - accuracy: 0.7340\n",
            "Epoch 115: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5964 - accuracy: 0.7340 - val_loss: 0.6102 - val_accuracy: 0.7296 - lr: 0.0100\n",
            "Epoch 116/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6045 - accuracy: 0.7291\n",
            "Epoch 116: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6046 - accuracy: 0.7290 - val_loss: 0.5761 - val_accuracy: 0.7519 - lr: 0.0100\n",
            "Epoch 117/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6052 - accuracy: 0.7310\n",
            "Epoch 117: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6050 - accuracy: 0.7311 - val_loss: 0.5746 - val_accuracy: 0.7495 - lr: 0.0100\n",
            "Epoch 118/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5993 - accuracy: 0.7341\n",
            "Epoch 118: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 37s 97ms/step - loss: 0.5993 - accuracy: 0.7341 - val_loss: 0.5622 - val_accuracy: 0.7608 - lr: 0.0100\n",
            "Epoch 119/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5990 - accuracy: 0.7330\n",
            "Epoch 119: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5988 - accuracy: 0.7331 - val_loss: 0.5834 - val_accuracy: 0.7308 - lr: 0.0100\n",
            "Epoch 120/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5975 - accuracy: 0.7326\n",
            "Epoch 120: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5975 - accuracy: 0.7326 - val_loss: 0.5428 - val_accuracy: 0.7611 - lr: 0.0100\n",
            "Epoch 121/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5970 - accuracy: 0.7349\n",
            "Epoch 121: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5970 - accuracy: 0.7349 - val_loss: 0.5429 - val_accuracy: 0.7577 - lr: 0.0100\n",
            "Epoch 122/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6076 - accuracy: 0.7307\n",
            "Epoch 122: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6074 - accuracy: 0.7308 - val_loss: 0.5461 - val_accuracy: 0.7639 - lr: 0.0100\n",
            "Epoch 123/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6036 - accuracy: 0.7292\n",
            "Epoch 123: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6036 - accuracy: 0.7292 - val_loss: 0.5490 - val_accuracy: 0.7603 - lr: 0.0100\n",
            "Epoch 124/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5984 - accuracy: 0.7318\n",
            "Epoch 124: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5985 - accuracy: 0.7318 - val_loss: 0.5989 - val_accuracy: 0.7291 - lr: 0.0100\n",
            "Epoch 125/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5973 - accuracy: 0.7356\n",
            "Epoch 125: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5972 - accuracy: 0.7357 - val_loss: 0.5399 - val_accuracy: 0.7712 - lr: 0.0100\n",
            "Epoch 126/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6015 - accuracy: 0.7322\n",
            "Epoch 126: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6014 - accuracy: 0.7322 - val_loss: 0.5825 - val_accuracy: 0.7401 - lr: 0.0100\n",
            "Epoch 127/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6084 - accuracy: 0.7305\n",
            "Epoch 127: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6085 - accuracy: 0.7305 - val_loss: 0.5679 - val_accuracy: 0.7565 - lr: 0.0100\n",
            "Epoch 128/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5989 - accuracy: 0.7349\n",
            "Epoch 128: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5990 - accuracy: 0.7347 - val_loss: 0.5748 - val_accuracy: 0.7334 - lr: 0.0100\n",
            "Epoch 129/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.6019 - accuracy: 0.7314\n",
            "Epoch 129: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.6020 - accuracy: 0.7314 - val_loss: 0.5758 - val_accuracy: 0.7421 - lr: 0.0100\n",
            "Epoch 130/200\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.5995 - accuracy: 0.7307\n",
            "Epoch 130: val_loss did not improve from 0.51710\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.5994 - accuracy: 0.7307 - val_loss: 0.5811 - val_accuracy: 0.7498 - lr: 0.0100\n",
            "Epoch 130: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y, evaluation = model.predict(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4kritgNdWlc",
        "outputId": "ecd378d2-a882-46be-cb10-56d279aca541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - 1s 14ms/step - loss: 0.5471 - accuracy: 0.7702\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.72      0.75      1049\n",
            "           1       0.75      0.82      0.78      1041\n",
            "           2       0.79      0.78      0.79      1086\n",
            "           3       0.76      0.76      0.76       984\n",
            "\n",
            "    accuracy                           0.77      4160\n",
            "   macro avg       0.77      0.77      0.77      4160\n",
            "weighted avg       0.77      0.77      0.77      4160\n",
            "\n",
            "F1-score is computed based on macro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/1f82MWoOupEhiZHNDkL9aV7yGNJdcjrB8/view?usp=sharing\n",
        "!gdown  --id 1f82MWoOupEhiZHNDkL9aV7yGNJdcjrB8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M957uVWYwzH9",
        "outputId": "8fb110a3-fa01-4a94-d0e3-01d0e10fb0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1f82MWoOupEhiZHNDkL9aV7yGNJdcjrB8\n",
            "To: /content/x_test.npy\n",
            "100% 794M/794M [00:03<00:00, 204MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = np.load('/content/x_test.npy')"
      ],
      "metadata": {
        "id": "XEIQzYXxEBbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape"
      ],
      "metadata": {
        "id": "83g1jK-yEM1z",
        "outputId": "658218fc-ad99-40f9-f309-c26f7371f042",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 62, 4000)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sub = np.expand_dims(test[:,:,::10], axis = 1)"
      ],
      "metadata": {
        "id": "n5Ft_nWnWL_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sub.shape"
      ],
      "metadata": {
        "id": "h-42zUyBWqeo",
        "outputId": "bf340015-8672-4617-8c76-1988c1a65860",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 1, 62, 400)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_sub = np.zeros(400)"
      ],
      "metadata": {
        "id": "1ZUb121kmILs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_sub.shape"
      ],
      "metadata": {
        "id": "sTfaJ2oRKQ5D",
        "outputId": "2e4bb126-e88f-4ea7-f86c-18812f029ca2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400,)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred, evaluation = model.predict(test_sub, y_sub)"
      ],
      "metadata": {
        "id": "WaxZo7QNW2A_",
        "outputId": "5cb1250e-246e-4d38-ee8b-e2e63f7ea99b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 13ms/step - loss: 2.6269 - accuracy: 0.2225\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.22      0.36       400\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.22       400\n",
            "   macro avg       0.25      0.06      0.09       400\n",
            "weighted avg       1.00      0.22      0.36       400\n",
            "\n",
            "F1-score is computed based on macro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred"
      ],
      "metadata": {
        "id": "GR_jv3-2Keo6",
        "outputId": "e8913d64-cf68-4084-cee2-6713678f3ad9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'y_pred': array([0, 2, 2, 1, 0, 2, 0, 3, 1, 1, 0, 3, 1, 0, 1, 2, 2, 1, 3, 1, 1, 1,\n",
              "        0, 1, 2, 1, 2, 2, 0, 2, 2, 0, 1, 1, 1, 1, 0, 3, 1, 0, 3, 3, 0, 2,\n",
              "        2, 1, 1, 3, 1, 3, 3, 3, 1, 3, 3, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0,\n",
              "        3, 1, 0, 0, 3, 1, 2, 1, 2, 0, 3, 2, 0, 0, 3, 2, 1, 0, 1, 1, 1, 0,\n",
              "        3, 3, 2, 1, 0, 3, 2, 2, 3, 2, 3, 2, 3, 2, 0, 1, 2, 3, 2, 1, 1, 3,\n",
              "        0, 2, 2, 3, 0, 0, 3, 0, 3, 3, 2, 3, 0, 2, 2, 2, 3, 0, 3, 2, 0, 3,\n",
              "        1, 2, 2, 3, 2, 1, 2, 1, 0, 1, 2, 2, 3, 2, 1, 1, 3, 3, 0, 1, 3, 1,\n",
              "        0, 1, 3, 0, 0, 1, 3, 2, 3, 3, 2, 3, 2, 0, 2, 1, 3, 0, 2, 2, 2, 2,\n",
              "        2, 0, 2, 0, 2, 0, 2, 3, 2, 0, 1, 0, 3, 2, 2, 2, 2, 2, 1, 1, 1, 0,\n",
              "        2, 1, 2, 2, 0, 1, 2, 3, 3, 0, 2, 1, 3, 2, 2, 2, 2, 3, 1, 2, 3, 3,\n",
              "        1, 3, 0, 2, 2, 0, 2, 0, 3, 3, 1, 2, 2, 2, 2, 2, 3, 3, 1, 1, 2, 2,\n",
              "        3, 2, 2, 2, 2, 0, 1, 2, 3, 3, 1, 2, 0, 0, 2, 1, 2, 2, 1, 1, 3, 0,\n",
              "        2, 1, 3, 3, 1, 3, 0, 1, 2, 3, 0, 1, 0, 1, 1, 2, 1, 0, 1, 0, 0, 2,\n",
              "        0, 1, 1, 1, 2, 3, 1, 3, 0, 0, 2, 1, 2, 3, 0, 0, 1, 0, 1, 3, 0, 1,\n",
              "        1, 2, 1, 1, 1, 2, 3, 1, 0, 2, 1, 2, 1, 3, 1, 0, 1, 1, 0, 0, 2, 3,\n",
              "        0, 0, 1, 2, 3, 2, 3, 1, 0, 3, 3, 1, 0, 2, 0, 3, 0, 2, 3, 3, 1, 1,\n",
              "        1, 1, 2, 1, 2, 3, 2, 0, 1, 0, 3, 1, 0, 1, 3, 2, 2, 2, 1, 2, 1, 2,\n",
              "        0, 1, 1, 3, 3, 1, 1, 0, 1, 2, 0, 2, 2, 2, 3, 1, 1, 2, 1, 1, 3, 0,\n",
              "        3, 3, 0, 1]),\n",
              " 'y_true': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.])}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred['y_pred']"
      ],
      "metadata": {
        "id": "1ibeRb6Lm0Ay",
        "outputId": "b49e246c-d041-479e-9f04-4f1060abcc00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 2, 1, 0, 2, 0, 3, 1, 1, 0, 3, 1, 0, 1, 2, 2, 1, 3, 1, 1, 1,\n",
              "       0, 1, 2, 1, 2, 2, 0, 2, 2, 0, 1, 1, 1, 1, 0, 3, 1, 0, 3, 3, 0, 2,\n",
              "       2, 1, 1, 3, 1, 3, 3, 3, 1, 3, 3, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0,\n",
              "       3, 1, 0, 0, 3, 1, 2, 1, 2, 0, 3, 2, 0, 0, 3, 2, 1, 0, 1, 1, 1, 0,\n",
              "       3, 3, 2, 1, 0, 3, 2, 2, 3, 2, 3, 2, 3, 2, 0, 1, 2, 3, 2, 1, 1, 3,\n",
              "       0, 2, 2, 3, 0, 0, 3, 0, 3, 3, 2, 3, 0, 2, 2, 2, 3, 0, 3, 2, 0, 3,\n",
              "       1, 2, 2, 3, 2, 1, 2, 1, 0, 1, 2, 2, 3, 2, 1, 1, 3, 3, 0, 1, 3, 1,\n",
              "       0, 1, 3, 0, 0, 1, 3, 2, 3, 3, 2, 3, 2, 0, 2, 1, 3, 0, 2, 2, 2, 2,\n",
              "       2, 0, 2, 0, 2, 0, 2, 3, 2, 0, 1, 0, 3, 2, 2, 2, 2, 2, 1, 1, 1, 0,\n",
              "       2, 1, 2, 2, 0, 1, 2, 3, 3, 0, 2, 1, 3, 2, 2, 2, 2, 3, 1, 2, 3, 3,\n",
              "       1, 3, 0, 2, 2, 0, 2, 0, 3, 3, 1, 2, 2, 2, 2, 2, 3, 3, 1, 1, 2, 2,\n",
              "       3, 2, 2, 2, 2, 0, 1, 2, 3, 3, 1, 2, 0, 0, 2, 1, 2, 2, 1, 1, 3, 0,\n",
              "       2, 1, 3, 3, 1, 3, 0, 1, 2, 3, 0, 1, 0, 1, 1, 2, 1, 0, 1, 0, 0, 2,\n",
              "       0, 1, 1, 1, 2, 3, 1, 3, 0, 0, 2, 1, 2, 3, 0, 0, 1, 0, 1, 3, 0, 1,\n",
              "       1, 2, 1, 1, 1, 2, 3, 1, 0, 2, 1, 2, 1, 3, 1, 0, 1, 1, 0, 0, 2, 3,\n",
              "       0, 0, 1, 2, 3, 2, 3, 1, 0, 3, 3, 1, 0, 2, 0, 3, 0, 2, 3, 3, 1, 1,\n",
              "       1, 1, 2, 1, 2, 3, 2, 0, 1, 0, 3, 1, 0, 1, 3, 2, 2, 2, 1, 2, 1, 2,\n",
              "       0, 1, 1, 3, 3, 1, 1, 0, 1, 2, 0, 2, 2, 2, 3, 1, 1, 2, 1, 1, 3, 0,\n",
              "       3, 3, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/1sC1GM4vE6FpQvdh9gOpyzO1AmyJWHlFz/view?usp=sharing\n",
        "!gdown  --id 1sC1GM4vE6FpQvdh9gOpyzO1AmyJWHlFz"
      ],
      "metadata": {
        "id": "5khF_tBNLDX-",
        "outputId": "c61e79f7-2207-4420-88b6-0c06a5671224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sC1GM4vE6FpQvdh9gOpyzO1AmyJWHlFz\n",
            "To: /content/sample_submission.csv\n",
            "100% 5.01k/5.01k [00:00<00:00, 9.27MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "EViwKk_SLcys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_df = pd.read_csv('/content/sample_submission.csv')\n",
        "for i,iter in enumerate(Y_pred['y_pred']):\n",
        "    sub_df.iloc[i,1] = int(iter)"
      ],
      "metadata": {
        "id": "dPNjlDJcW7nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(sub_df.iloc[1,1])"
      ],
      "metadata": {
        "id": "_IkEm99bQ3r9",
        "outputId": "9de3bf80-787a-422a-9e5d-689b0a12689c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.float64"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_df"
      ],
      "metadata": {
        "id": "jbAVvkuhmxCv",
        "outputId": "e05a8e47-e27e-4dc3-9736-81d61b153b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sample_id  prediction\n",
              "0           1         0.0\n",
              "1           2         2.0\n",
              "2           3         3.0\n",
              "3           4         1.0\n",
              "4           5         0.0\n",
              "..        ...         ...\n",
              "795      f396         NaN\n",
              "796      f397         NaN\n",
              "797      f398         NaN\n",
              "798      f399         NaN\n",
              "799      f400         NaN\n",
              "\n",
              "[800 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-777c883b-cc18-463f-b354-63d04775400b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_id</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>f396</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>f397</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>f398</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>f399</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>f400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows  2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-777c883b-cc18-463f-b354-63d04775400b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-777c883b-cc18-463f-b354-63d04775400b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-777c883b-cc18-463f-b354-63d04775400b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_df['prediction'][0] = 0\n",
        "sub_df['prediction'][1] = 2\n",
        "sub_df['prediction'][2] = 3"
      ],
      "metadata": {
        "id": "JRxZ6db_m2L-",
        "outputId": "14be2134-39c2-44b7-b1d3-7cefdb943c45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_df['prediction'][0:400] = sub_df['prediction'][0:400].apply(lambda x : str(x)[0])\n",
        "sub_df['prediction'][0:400] = sub_df['prediction'][0:400].apply(lambda x : int(str(x)[0]))"
      ],
      "metadata": {
        "id": "HPwDNa_am2nd",
        "outputId": "2e614ffe-4ae5-4592-856e-e3d0f734cbc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(sub_df['prediction'][5])"
      ],
      "metadata": {
        "id": "GrZx4jejm5mw",
        "outputId": "de656bac-cd5d-429d-a0d6-747a3f6cdaaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_df.to_csv('/content/juuu.csv',index = False)"
      ],
      "metadata": {
        "id": "dAh1QzRBm89X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aRJ89XAuUCvN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}